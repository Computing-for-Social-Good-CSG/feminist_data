# Bias Reporting Tool and Data Feminism Research Paper Dataset 

[Read the Paper - TBD][Use the Bias Reporting Tool - TBD] 

## What's in this repository? 
There are several items that may be useful to researchers thinking about bias research and ethics reporting. 
1. A link to the live dataset bias reporting tool.
   - This tool is a form that dynamically adapts to your input to suggest different forms of potential bias in your dataset. It then summarizes the results in a standardized format. It's designed for Natural Langauge Processing (NLP) researchers and paper authors, but anyone can use it. 
   - Please note this is a prototype, and there are several limitations (i.e. not every language and data source has detailed suggestions).
2. Dataset of NLP Research Papers
   - In our research, we aggregated a datasets of the titles, abstracts, and metadata from ten years worth of research papers the leading NLP journal.
   - We do not make our scored sample generated using the Feminist Datacodebook available due to ethical considerations. 
   - More information on the dataset can be found [here](## Dataset of NLP Research Papers).
3. Code for the Bias Reporting Tool.
   - The tool is built using the Typeform API (more implementation information to come).
   - We make the code available for two reasons: so that users of the tool have transparency on how the reports are generated, and so that others can fork or contribute to the tool. If you do fork our code, we ask you cite our repository as per the MIT License.

## Dataset of NLP Research Papers 
The dataset includes all papers from the ACL Anthology from January 1, 2014 to December 31st, 2023. We include metadata from both the [Association for Computational Linguistics (ACL) Anthology](https://aclanthology.org/) and [Semantic Scholar](https://aclanthology.org/N18-3011/). The features include: 
1. Paper Title
2. Abstract
3. Authors
4. Citation count
5. Publication venue
6. Dataset language (Arabic or English). All papers are written in English.
7. Research topic (as generated by BERTopic). Details on BERTopic classification process available in the [paper - TBD]. 

Additional notes:
- The English dataset has been filtered to exclude papers specifically relating to languages other than English. For example, Papers with "French" or "Spanish" in the title would have been excluded.
- There are notable imperfections in the topic classifications, especiially in cases where papers appeared to belong to more than one category.

[See the full dataset bias report - TBD]
  
## How do I cite this work? 
### Citation 
> Cass Mayeda, Arinjay Singh, Arnav Mahale, Laila Shereen Sakr, and Mai ElSherief. 2025. Applying Data Feminism Principles to Assess Bias in English and Arabic NLP Research. In * *The 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’25), June 23–26, 2025, Athens, Greece* *. ACM, New York, NY, USA, 24 pages. https://doi.org/10.1145/3715275.3732119
