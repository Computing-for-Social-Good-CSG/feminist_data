# feminist_data

[Read the Paper - TBD][Use the Bias Reporting Tool - TBD] 

## What's in this repository? 
There are several items that may be useful to researchers thinking about bias research and ethics reporting. 
1. A link to the live dataset bias reporting tool.
   - This tool is a form that dynamically adapts to your input to suggest different forms of potential bias in your dataset. It then summarizes the results in a standardized format. It's designed for Natural Langauge Processing (NLP) researchers and paper authors, but anyone can use it. 
   - Please note this is a prototype, and there are several limitations (i.e. not every language and data source has detailed suggestions).
2. Dataset: 10 Years of NLP Research Papers
   - In our research, we aggregated a datasets of the titles, abstract, and metadata from ten years worth of NLP research papers in the ACL Anthology.
   - We do not make our scores generating using the Feminist Datacodebook available due to ethical considerations. 
   - More information on the dataset can be found [here].
3. Code for the Bias Reporting Tool.
   - The tool is built using the Typeform API (more implementation information to come).
   - We make the code available for two reasons: so that users of the tool have transparency on how the reports are generated, and so that others can fork or contribute to the tool. If you do fork our code, we ask you cite our repository as per the MIT License.
  
## How do I cite this work? 
### Citation 
> Cass Mayeda, Arinjay Singh, Arnav Mahale, Laila Shereen Sakr, and Mai ElSherief. 2025. Applying Data Feminism Principles to Assess Bias in English and Arabic NLP Research. In * *The 2025 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’25), June 23–26, 2025, Athens, Greece* *. ACM, New York, NY, USA, 24 pages. https://doi.org/10.1145/3715275.3732119
